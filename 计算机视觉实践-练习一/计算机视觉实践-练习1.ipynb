{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "————————————————————————————————————————————————————\n",
    "\n",
    "实现图像拼接步骤\n",
    "\n",
    "1. 采用sift特征检测算法检测两幅图像的关键特征点\n",
    "\n",
    "2. 采用knn检测函数进行特征匹配并可视化\n",
    "\n",
    "3. 从所匹配的全部关键点中筛选出优秀的特征点（基于距离筛选）\n",
    "\n",
    "4. 用 RANSAC 算法来计算透视变换矩阵 H\n",
    "\n",
    "5. 使用透视变换矩阵H对图片1/2进行透视变换，得到变换后的结果图像\n",
    "\n",
    "6. 将图片2/1叠加在变换后的图像result的左上角位置，实现图像融合\n",
    "\n",
    "7. 图像融合后会出现黑色边界区域，通过中值滤波去除黑色区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ################################\n",
    "# 使用 OpenCV 进行 SIFT 特征提取\n",
    "# ################################\n",
    "def Get_features(gray_image):\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "    \n",
    "    return keypoints, descriptors\n",
    "\n",
    "# ################################\n",
    "#           获取图片\n",
    "# ################################\n",
    "def Get_img(image_path):\n",
    "    image =  cv2.imread(image_path)\n",
    "    #OpenCV中读取的图像是以BGR（蓝绿红）顺序进行编码的，需要将图像转换为RGB格式进行处理\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #防止图片过大\n",
    "    img = cv2.resize(gray_image, (1028, 762))\n",
    "    return img\n",
    "\n",
    "# ################################\n",
    "# 采用knn检测函数进行特征匹配\n",
    "# 获取匹配的关键点用以可视化\n",
    "# ################################\n",
    "def Get_match(feature_1,feature_2):\n",
    "    bf = cv2.BFMatcher()\n",
    "    rawMatches = bf.knnMatch(feature_1, feature_2, k=2)\n",
    "\n",
    "    matches = []\n",
    "    #过滤\n",
    "    for m,n in rawMatches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                matches.append(m)\n",
    "                        \n",
    "    return  matches\n",
    "\n",
    "\n",
    "# ################################\n",
    "#         显示图片并保存\n",
    "# ################################\n",
    "def show_img(name,img):\n",
    "    #获取图片时转换为RGB格式，显示图片则需要转换为BGR\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow(name,img)\n",
    "    cv2.imwrite('img/'+ name + '.jpg', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "# #################################################################\n",
    "# 采用knn检测函数进行特征匹配\n",
    "# 用 RANSAC 算法来计算透视变换矩阵 H，并返回变换矩阵、匹配特征点对和状态信息\n",
    "# #################################################################\n",
    "\n",
    "def matchKeypoints(keypoints_1, keypoints_2, features_1, features_2, ratio, reprojThresh):\n",
    "        # 创建BFMatcher对象\n",
    "        matcher = cv2.BFMatcher()\n",
    "        # 使用BFMatcher进行特征点匹配\n",
    "        rawMatches = matcher.knnMatch(features_1, features_2, 2)\n",
    "        \n",
    "        #受cv2.findHomography()函数输入限制，更改类型\n",
    "        keypoints_1 = np.float32([kp.pt for kp in keypoints_1])\n",
    "        keypoints_2 = np.float32([kp.pt for kp in keypoints_2])\n",
    "        \n",
    "        matches = []\n",
    "        for m in rawMatches:\n",
    "            if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
    "                matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "\n",
    "       #如果筛选后的匹配特征点对数量大于 4，则将这些特征点对转换为 NumPy 数组\n",
    "        if len(matches) > 4:\n",
    "            ptsA = np.float32([keypoints_1[i] for (_, i) in matches])\n",
    "            ptsB = np.float32([keypoints_2[i] for (i, _) in matches])\n",
    "            \n",
    "            #用 RANSAC 算法来计算透视变换矩阵 H，并返回变换矩阵、匹配特征点对和状态信息。\n",
    "            (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, reprojThresh)\n",
    "            \n",
    "            return (matches, H, status)\n",
    "        \n",
    "        else:\n",
    "            print(\"可匹配的特征点数量较低\")\n",
    "\n",
    "# ################################       \n",
    "# 裁剪掉拼接后图像中的黑色区域  \n",
    "# ################################\n",
    "\n",
    "def remove_black_edge(image):\n",
    "    # 使用中值滤波器对输入的图像进行中值滤波，目的是去除可能存在于黑色边缘中的噪声干扰\n",
    "    img = cv2.medianBlur(image, 5)\n",
    "    \n",
    "    #使用阈值处理函数对中值滤波后的图像进行二值化处理。将像素值低于阈值15的像素设为0（黑色），将像素值高于阈值的像素设为255（白色）\n",
    "    b = cv2.threshold(img, 15, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #b为阈值处理后的图像以及阈值处理的返回值。而我们只需要处理后的图像，因此取返回值的第二个元素b[1]\n",
    "    binary_image = b[1]\n",
    "    binary_image = cv2.cvtColor(binary_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #获取原始图像的长和宽\n",
    "    x = binary_image.shape[0]\n",
    "    y = binary_image.shape[1]\n",
    "    edges_x = []\n",
    "    edges_y = []\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            if binary_image[i][j] == 255:\n",
    "                edges_x.append(i)\n",
    "                edges_y.append(j)\n",
    "\n",
    "    #重新设置图像的四点位置\n",
    "    left = min(edges_x)\n",
    "    right = max(edges_x)\n",
    "    width = right - left\n",
    "    bottom = min(edges_y)\n",
    "    top = max(edges_y)\n",
    "    height = top - bottom\n",
    "\n",
    "    pre1_picture = image[left:left + width, bottom:bottom + height]\n",
    "    return pre1_picture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    image_path_1 = 'img/1.jpg'\n",
    "    image_path_2 = 'img/2.jpg'\n",
    "\n",
    "    image_1 = Get_img(image_path_1)\n",
    "    image_2 = Get_img(image_path_2)\n",
    "\n",
    "    \n",
    "    keypoints_1, descriptors_1 = Get_features(image_1)\n",
    "    keypoints_2, descriptors_2 = Get_features(image_2)\n",
    "\n",
    "    image_with_keypoints_1 = cv2.drawKeypoints(image_1, keypoints_1, None)\n",
    "    image_with_keypoints_2 = cv2.drawKeypoints(image_2, keypoints_2, None)\n",
    "    show_img('Image with Keypoints_1',image_with_keypoints_1)\n",
    "    show_img('Image with Keypoints_2',image_with_keypoints_2)\n",
    "    \n",
    "    #显示图片的关键点\n",
    "    match = Get_match(descriptors_1,descriptors_2)\n",
    "    #绘制K近邻匹配结果\n",
    "    image_with_match = cv2.drawMatches(image_1, keypoints_1, image_2, keypoints_2,match,None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    show_img('Image with matches',image_with_match)\n",
    "    \n",
    "   \n",
    "    M = matchKeypoints(keypoints_2, keypoints_1, descriptors_2, descriptors_1, ratio = 0.75, reprojThresh = 4.0)\n",
    "    if M is None:\n",
    "        print(\"Error!\")\n",
    "    (matches, H, status) = M\n",
    "    \n",
    "    #使用透视变换矩阵H对image_1进行透视变换，得到变换后的结果图像result\n",
    "    result = cv2.warpPerspective(image_2, H, ((image_1.shape[1] + image_2.shape[1])*2, max(image_1.shape[0],image_2.shape[0])))\n",
    "    \n",
    "    result_1 = remove_black_edge(result)\n",
    "    #由于无法确定应当对哪张图片进行透视变换，因此判断 \n",
    "    if np.size(result_1) <  np.size(image_2)*0.85:\n",
    "        #交换图片\n",
    "        image = image_1\n",
    "        image_1 = image_2\n",
    "        image_1 = image\n",
    "        M = matchKeypoints(keypoints_1, keypoints_2, descriptors_1, descriptors_2, ratio = 0.75, reprojThresh = 4.0)\n",
    "        (matches, H, status) = M\n",
    "        #使用透视变换矩阵H对image_1进行透视变换，得到变换后的结果图像result\n",
    "        result = cv2.warpPerspective(image_2, H, (image_1.shape[1] + image_2.shape[1], max(image_1.shape[0],image_2.shape[0])))\n",
    "        \n",
    "    show_img('images after perspective',result)\n",
    "\n",
    "    #将image_2与变换后的图像result实现图像融合\n",
    "    result[0:image_1.shape[0], 0:image_1.shape[1]] = image_1\n",
    "#     result[0:image_1.shape[0], 0:image_1.shape[1]] = np.maximum(image_1, result[0:image_1.shape[0], 0:image_1.shape[1]])\n",
    "    show_img('result images',result)\n",
    "    \n",
    "    \n",
    "    result_2 = remove_black_edge(result)\n",
    "    show_img('result images after remove black edge',result_2)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
